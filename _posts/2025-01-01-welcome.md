---
layout: post
title: 1 - The Alignment Gap
date: 2026-02-26
description: First post on the new website.
tags: general
categories: updates
giscus_comments: true
---

# The alignment gap

### Intro

Welcome to the new and shiny blogpost section of this website! I decided to use this space as a informal personal diary, collecting resources for my future projects. For the sake of my sanity I'll keep the blog informal, using minimal structure and treating it more as a flow of conscience space than everything else.

I decided to dedicate this first post to what I call the "alignment gap". As of today &mdash; *26/02/26* &mdash; I believe that we are starting to see the early signs of a mis-alignent between the conceptual goal we had for AI and it's effective use. In short, instead of helping humanity to advance, we are running the risk of creating systems that could behave against our interests, both willingly and unwillingly. This is especially true right now, as we are seeing the first signs of agents actually being embodied in the real world &mdash; humanoid robots &mdash; and collaborating with each other in unsupervised settings &mdash; Moltobook &mdash;. This gap - unless properly acknowledge - will grow wider and wider.

### The starting point